Chapter 6: Exercise 10 
======================

## a
```{r}
set.seed(1)
p = 20
n = 1000
x = matrix(rnorm(n*p), n, p)
B = rnorm(p)
B[3] = 0
B[4] = 0
B[9] = 0
B[19] = 0
B[10] = 0
eps = rnorm(p)
y = x %*% B + eps

data.full = as.data.frame(x)
colnames(data.full) = paste("col", 1:p, sep="")
data.full$y = y
```

## b
```{r}
train = sample(seq(1000), 100, replace = FALSE)
y.train = data.full$y[train]
y.test = data.full$y[-train]
x.train = model.matrix(y~., data=data.full[train,])
x.test = model.matrix(y~., data=data.full[-train,])
```

## c
```{r}
library(leaps)
regfit.full = regsubsets(y~., data=data.full[train,], nvmax=p)
val.errors = rep(NA, p)
for (i in 1:p) {
  coefi = coef(regfit.full, id=i)
  pred = x.train[, names(coefi)] %*% coefi
  val.errors[i] = mean((y.train - pred)^2)
}
plot(val.errors, ylab="Training MSE", pch=19, type="b")
```

## d
```{r}
val.errors = rep(NA, p)
for (i in 1:p) {
  coefi = coef(regfit.full, id=i)
  pred = as.matrix(x.test[, names(coefi)]) %*% coefi
  val.errors[i] = mean((y.test - pred)^2)
}
plot(val.errors, ylab="Test MSE", pch=19, type="b")
```

## e
```{r}
which.min(val.errors)
```
16 parameter model has the smallest test MSE.

## f
```{r}
coef(regfit.full, id=16)
```
Caught all but one zeroed out coefficient at x.19.

## g
```{r}
val.errors = rep(NA, p)
a = rep(NA, p)
b = rep(NA, p)
x_cols = colnames(x, do.NULL = FALSE, prefix = "col")
for (i in 1:p) {
  coefi = coef(regfit.full, id=i)
  a[i] = length(coefi)-1
  b[i] = sqrt(
    sum((B[x_cols %in% names(coefi)] - coefi[names(coefi) %in% x_cols])^2) +
    sum(B[!(x_cols %in% names(coefi))])^2)
}
plot(x=a, y=b, xlab="number of coefficients",
     ylab="error between estimated and true coefficients")
which.min(b)
```
Model with 9 coefficients (10 with intercept) minimizes the error between the 
estimated and true coefficients. Test error is minimized with 16 parameter model.
A better fit of true coefficients as measured here doesn't mean the model will have
a lower test MSE.
